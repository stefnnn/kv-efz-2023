{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read text file from kv-efz-2023.txt\n",
      "Parsed 5 areas with a total of 28 sections and 341 competencies.\n",
      "Wrote parsed plan to kv-efz-2023.json\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Parse KV-EFZ Bildungsplan (v2023) from PDF / plain text to JSON\n",
    "#\n",
    "# Input: \n",
    "# Bildungsplan Kauffrau/Kaufmann mit eidgenössischem Fähigkeitszeugnis (EFZ)\n",
    "# vom 24. Juni 2021 (Stand am 1. Juni 2023)\n",
    "# URL: https://www.skkab.ch/download/bildungsplan/\n",
    "# PDF: https://www.skkab.ch/download/bildungsplan/?wpdmdl=6259&refresh=664edfbc7cc9c1716445116&ind=1685604344061&filename=DE_BiPla_SKKAB_inkl_Branchenspezifika_Version-01.06.2023.pdf\n",
    "#\n",
    "# License: MIT\n",
    "###\n",
    "\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Input file path\n",
    "FILE_PATH = os.getenv(\"FILE_PATH\", \"kv-efz-2023.txt\")\n",
    "OUTPUT_PATH = os.getenv(\"OUTPUT_PATH\", \"kv-efz-2023.json\")\n",
    "DEBUG_PRINT = os.getenv(\"DEBUG_PRINT\", \"false\").lower() == \"true\"\n",
    "\n",
    "# Regular expression to match competency identifiers (e.g. a1.bs1)\n",
    "RX_COMPETENCY_IDENTIFIER = r'(\\w\\d+\\.(?:bs|bt)\\d+\\w?)\\n'\n",
    "RX_AREA_IDENTIFIER = r'(Handlungskompetenzbereich [a-z]):'\n",
    "RX_SECTION_IDENTIFIER = r'(Handlungskompetenz [a-z][0-9]):'\n",
    "\n",
    "# Short helper function to clean up text from the PDF (hyphens, newlines, tabs)\n",
    "def clean_text(text: str):\n",
    "    return text.strip().replace('-\\n', '').replace('\\n', ' ').replace('\\t', ' ')\n",
    "\n",
    "# The actual parser function\n",
    "def parse_plan(file_path: str) -> list[dict]:\n",
    "    # Read the plain text file\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "        print(f\"Read text file from {file_path}\")\n",
    "    \n",
    "    # Split by main areas\n",
    "    data = re.split(RX_AREA_IDENTIFIER, text)\n",
    "    plan: list[dict] = []\n",
    "    \n",
    "    # Cycle through main areas\n",
    "    for area_code, area_raw in zip(data[1::2], data[2::2]):\n",
    "        # Split according to sub-sections\n",
    "        content_raw = re.split(RX_SECTION_IDENTIFIER, area_raw)\n",
    "\n",
    "        # The first element contains the area title (i.e. before the first sub-section identifier)\n",
    "        area_title = clean_text(content_raw[0])\n",
    "        area_data = {'code': area_code, 'title': area_title, 'sections': []}\n",
    "        \n",
    "        # Cycle through sub-sections\n",
    "        for section_code, section_raw in zip(content_raw[1::2], content_raw[2::2]):\n",
    "            # Split according to competencies, seperated by identifiers like a1.bs1\n",
    "            # bs = Berufsschule, bt = Betrieb\n",
    "            competencies_list = re.split(RX_COMPETENCY_IDENTIFIER, section_raw, flags=re.DOTALL)\n",
    "            # The first element contains the section title (first line) and the description (rest)\n",
    "            section_title, section_desc = re.split(r'\\n', competencies_list[0], maxsplit=1)\n",
    "\n",
    "            # Create a dictionary from the competencies\n",
    "            competency_keys = competencies_list[1::2]\n",
    "            competency_descs = [clean_text(text) for text in competencies_list[2::2]]\n",
    "            competencies = dict(zip(competency_keys, competency_descs))\n",
    "            section_data = {'code': section_code, 'title': clean_text(section_title), \"desc\": clean_text(section_desc), 'competencies': competencies}\n",
    "\n",
    "            # Append the section to the area\n",
    "            area_data['sections'].append(section_data)\n",
    "\n",
    "        # Append the area to the plan\n",
    "        plan.append(area_data)\n",
    "\n",
    "    num_sections = sum([len(area['sections']) for area in plan])\n",
    "    num_competencies = sum([len(section['competencies']) for area in plan for section in area['sections']])\n",
    "    print(f\"Parsed {len(plan)} areas with a total of {num_sections} sections and {num_competencies} competencies.\")\n",
    "    return plan\n",
    "\n",
    "# Print the parsed plan in a human-readable format\n",
    "def debug_plan(parsed: list[dict]):\n",
    "    for area in parsed:\n",
    "        print(f'\\n\\n\\n{area[\"title\"].upper()}\\n{60*\"=\"}')\n",
    "        for section in area['sections']:\n",
    "            print(f'\\n{section[\"code\"]} - {section[\"title\"]}\\n{60*\"-\"}')\n",
    "            for title, desc in section['competencies'].items():\n",
    "                print(f'  - {title} // {desc}')\n",
    "\n",
    "# Parse and write the plan to a JSON file\n",
    "def main():\n",
    "    plan = parse_plan(FILE_PATH)\n",
    "\n",
    "    # Write output to JSON file\n",
    "    with open(OUTPUT_PATH, 'w') as file:\n",
    "        json.dump(plan, file, indent=2)\n",
    "        print(f\"Wrote parsed plan to {OUTPUT_PATH}\")\n",
    "\n",
    "    if DEBUG_PRINT: \n",
    "        debug_plan(plan)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
